{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/behrangEhi/ML-DL-Projects/blob/main/svm_dual_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing Dual Support Vector Machine (SVM) Optimization in Google Colab\n",
        "\n",
        "Introduction:\n",
        "This Google Colab notebook demonstrates the implementation of a dual optimization algorithm for training a Support Vector Machine (SVM) classifier. The code provides functions for creating a normalized and centered kernel, as well as the core SVM dual optimization routine.\n",
        "\n",
        "The main objectives of this Colab are:\n",
        "\n",
        "1. To walk through the process of implementing a dual SVM optimization algorithm in Python.\n",
        "2. To show how to leverage the powerful computational resources and libraries available in Google Colab to train and evaluate SVM models.\n",
        "3. To provide a reusable code template that can be adapted and extended for various SVM-based machine learning tasks.\n",
        "\n",
        "By working through this Colab, you will gain a deeper understanding of the dual SVM optimization approach and how to apply it using Python and the libraries available in the Colab environment.\n",
        "\n",
        "Let's get started!"
      ],
      "metadata": {
        "id": "wq6GLwtGYHaJ"
      },
      "id": "wq6GLwtGYHaJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1649dc25",
      "metadata": {
        "id": "1649dc25"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def create_normalized_centered_kernel(K):\n",
        "    n = K.shape[0]\n",
        "    centered_K = (np.identity(n) - (1/n)*np.ones((n,n))).dot(K).dot(np.identity(n) - (1/n)*np.ones((n,n)))\n",
        "    W = np.diag(np.diag(centered_K))\n",
        "    normalized_centered_K = np.power(W,-1/2, where=(W!=0)).dot(centered_K).dot(np.power(W,-1/2, where=(W!=0)))\n",
        "    return normalized_centered_K\n",
        "\n",
        "def SVM_DUAL(D,y,Kernel,C,epsilon,loss):\n",
        "    n = D.shape[0]\n",
        "\n",
        "    if loss==\"hinge\":\n",
        "        K = Kernel\n",
        "    elif loss==\"quadratic\":\n",
        "        K = Kernel + (1/(2*C))*np.eye(n)\n",
        "\n",
        "    K_q = K + np.ones(K.shape)\n",
        "    eta = 1/np.diagonal(K_q)\n",
        "    t = 0\n",
        "    alphas = [np.zeros((n,1))]\n",
        "    while True:\n",
        "        alpha = np.copy(alphas[t])\n",
        "        for k in range(n):\n",
        "            alpha[k] = alpha[k] + eta[k]*(1-y[k]*np.sum(np.multiply(alpha,np.multiply(y,K_q[:,k]))))\n",
        "            if alpha[k] < 0:\n",
        "                alpha[k] = 0\n",
        "            if loss==\"hinge\" and alpha[k] > C:\n",
        "                alpha[k] = C\n",
        "        alphas.append(alpha)\n",
        "        t+=1\n",
        "        if np.linalg.norm(alphas[-1]-alphas[-2]) <= epsilon:\n",
        "            break\n",
        "    yhat = np.zeros((n,1))\n",
        "    for k in range(n):\n",
        "        yhat[k] = np.sum(np.multiply(alphas[-1],np.multiply(y,K_q[:,k])))\n",
        "    yhat = np.sign(yhat)\n",
        "\n",
        "    return alphas[-1],yhat\n",
        "\n",
        "def print_results(alpha,yhat,kernel_type):\n",
        "    print(kernel_type,\":\")\n",
        "    num = 0\n",
        "    for i in range(len(alpha)):\n",
        "        if alpha[i][0]>0:\n",
        "            num+=1\n",
        "            print(\"i = \",i+1,\", alpha_i = \",alpha[i][0])\n",
        "    print(\"number of support vectors = \",num)\n",
        "    print(\"accuracy = \",np.sum([yhat[i][0]==y[i] for i in range(len(y))])/len(y))\n",
        "\n",
        "C=10\n",
        "epsilon = 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d5542c9",
      "metadata": {
        "id": "1d5542c9"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"iris-slwc.txt\",names=[\"length\",\"width\",\"class\"])\n",
        "D = data[[\"length\",\"width\"]]\n",
        "y = data[\"class\"].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40ebdda7",
      "metadata": {
        "id": "40ebdda7"
      },
      "outputs": [],
      "source": [
        "linear_Kernel = np.array(D.dot(D.T).pow(1))\n",
        "alpha,yhat = SVM_DUAL(D,y,create_normalized_centered_kernel(linear_Kernel),C,epsilon,\"hinge\")\n",
        "print_results(alpha,yhat,\"linear kernel\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b9ea057",
      "metadata": {
        "id": "1b9ea057"
      },
      "outputs": [],
      "source": [
        "homogeneous_quadrat_Kernel = np.array(D.dot(D.T).pow(2))\n",
        "alpha,yhat = SVM_DUAL(D,y,create_normalized_centered_kernel(homogeneous_quadrat_Kernel),C,epsilon,\"hinge\")\n",
        "print_results(alpha,yhat,\"homogeneous quadrat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7de6020e",
      "metadata": {
        "id": "7de6020e"
      },
      "outputs": [],
      "source": [
        "n = D.shape[0]\n",
        "inhomogeneous_quadrat_Kernel = np.array((D.dot(D.T)+1*np.ones((n,n))).pow(2))\n",
        "alpha,yhat = SVM_DUAL(D,y,create_normalized_centered_kernel(inhomogeneous_quadrat_Kernel),C,epsilon,\"hinge\")\n",
        "print_results(alpha,yhat,\"inhomogeneous quadrat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "246ccb92",
      "metadata": {
        "id": "246ccb92"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"iris-PC.txt\",delim_whitespace=True,names=[\"length\",\"width\",\"class\"])\n",
        "D = data[[\"length\",\"width\"]]\n",
        "y = data[\"class\"].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1573af1",
      "metadata": {
        "id": "f1573af1"
      },
      "outputs": [],
      "source": [
        "linear_Kernel = np.array(D.dot(D.T).pow(1))\n",
        "alpha,yhat = SVM_DUAL(D,y,create_normalized_centered_kernel(linear_Kernel),C,epsilon,\"hinge\")\n",
        "print_results(alpha,yhat,\"linear kernel\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23326fce",
      "metadata": {
        "id": "23326fce"
      },
      "outputs": [],
      "source": [
        "homogeneous_quadrat_Kernel = np.array(D.dot(D.T).pow(2))\n",
        "alpha,yhat = SVM_DUAL(D,y,create_normalized_centered_kernel(homogeneous_quadrat_Kernel),C,epsilon,\"hinge\")\n",
        "print_results(alpha,yhat,\"homogeneous quadrat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a349ed7",
      "metadata": {
        "id": "6a349ed7"
      },
      "outputs": [],
      "source": [
        "n = D.shape[0]\n",
        "inhomogeneous_quadrat_Kernel = np.array((D.dot(D.T)+1*np.ones((n,n))).pow(2))\n",
        "alpha,yhat = SVM_DUAL(D,y,create_normalized_centered_kernel(inhomogeneous_quadrat_Kernel),C,epsilon,\"hinge\")\n",
        "print_results(alpha,yhat,\"inhomogeneous quadrat\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}